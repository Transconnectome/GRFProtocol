### ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
### 01-B | simulation > backward_elimination
### (2)  | nonlinear-ours.R
### ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
### written by
### ---
### Jinwoo Lee & Maria Pak
### SNU Connectome Lab
### ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

library(grf)
library(ggplot2)

### _______________________________________________________________________ ####
### @@@ PART I. DEFAULT SETTING @@@ ####
## > I-1. Data Preparation ####
# assume we have simulation data using ../train_data_simulation.R.
data <- read.csv("../data/train_nonlin_weak.csv") 

Y <- data$y
W <- data$w
X <- subset(data, select = -c(y, theta, w, src_subject_id, site_id_l)) # total 149 covariates
site_id_l <- as.factor(data$site_id_l)                                 # for clustering variable

## > I-2. Results Template ####
result.models <- data.frame(matrix(ncol = 10))
colnames(result.models) <- c("var_num", "beta_ATE_est", "beta_ATE_p", "beta_ITE_est", "beta_ITE_p", 
                             "ATE_est", "ATE_se", "ATE_p", "min_e_hat", "max_e_hat")

## > I-3. Random Seeds ####
varimp.list <- colnames(X)
worst.var.list <- list()

n <- nrow(data)
full.var.num <- length(X)

n.seeds <- 5
n.trees <- 2000

# for reproduction using seeds below
seeds <- c(6406, 1553, 2976, 4302, 5960) # generated by 'sample(1:10000, size = n.seeds, replace = FALSE)'


### _______________________________________________________________________ ####
### @@@ PART II. MODEL FITTING @@@ ####
for (threshold in c(0:(full.var.num-1))) {
  
  ## > II-1. Covariates Update ####
  options(warn = 1)
  current.var.num <- full.var.num - threshold
  chosen.feature <- varimp.list
  
  assign(paste0("var_list_", current.var.num), chosen.feature)
  
  cf.thr.seed.list <- list() # for archiving mini forests
  
  X.tmp <- subset(X, select = chosen.feature)
  
  ## > II-2. Fitting 'Mini' Models Iteratively ####
  for (seed_idx in c(1:length(seeds))) {
    current.cf.thr.seed <- causal_forest(X.tmp, Y, W, 
                                         Y.hat = NULL, W.hat = NULL,
                                         clusters = site_id_l,   # clustering variable
                                         tune.parameters = "all",
                                         compute.oob.predictions = FALSE,
                                         num.trees = n.trees,
                                         num.threads = 12,
                                         seed = seeds[seed_idx])
    
    cf.thr.seed.list[[paste0("cf.thr.seed", seed_idx)]] = current.cf.thr.seed
  }
  
  ## > II-3. Performing Seed Ensembles and Making a 'Big' Model ####
  cf.thr.big <- merge_forests(cf.thr.seed.list, compute.oob.predictions = FALSE)
  print(paste0("[", threshold+1, "/", full.var.num, "] STEP 1 - The big forest with the ", current.var.num, " variables was created."))
  
  # cleaning the environment
  rm(cf.thr.seed.list)
  
  ## > II-4. Calibration Testing with the 'Big' Model ####
  fit.thr <- test_calibration(cf.thr.big)
  
  ## > II-5. ATE Estimation with the 'Big' Model ####
  ate.est.thr <- average_treatment_effect(cf.thr.big, method = "AIPW")[1]
  ate.se.thr <- average_treatment_effect(cf.thr.big, method = "AIPW")[2]
  ate.tstat.thr <- ate.est.thr / ate.se.thr
  ate.pvalue.thr <- 1.96 * (1 - pnorm(abs(ate.tstat.thr)))
  
  ## > II-6. Results Archiving ####
  # for calibration criteria
  beta_ATE.est <- fit.thr[1]
  beta_ATE.p <- fit.thr[7]
  beta_ITE.est <- fit.thr[2]
  beta_ITE.p <- fit.thr[8]
  
  # for overlap criteria
  min.e.hat <- min(cf.thr.big$W.hat) 
  max.e.hat <- max(cf.thr.big$W.hat) 
  
  result.models <- rbind(result.models, c(current.var.num, 
                                          beta_ATE.est, beta_ATE.p,
                                          beta_ITE.est, beta_ITE.p, 
                                          ate.est.thr, ate.se.thr, ate.pvalue.thr,
                                          min.e.hat, max.e.hat))
  
  print(paste0("[", threshold+1, "/", full.var.num, "] STEP 2 - The results from the big forest with the ", current.var.num, " variables were saved."))
  
  ## > II-7. Assessing Variable Importance for Next Iteration ####
  current.varimp <- c(variable_importance(cf.thr.big))
  names(current.varimp) <- colnames(X.tmp)
  current.varimp <- sort(current.varimp, decreasing = TRUE)
  worst.var <- names(current.varimp)[current.var.num]
  varimp.list <- varimp.list[varimp.list != worst.var] # exclude the feature with the lowest importance
  worst.var.list <- append(worst.var.list, worst.var)  # save the order of the excluded variables
  
  print(paste0("[", threshold+1, "/", full.var.num, "] STEP 3 - The covariates for next iteration were successfully updated."))
  print(paste0("[", threshold+1, "/", full.var.num, "] The excluded variable is ", worst.var, " and the number of left covariates is ", length(varimp.list), "."))
}

result.models <- result.models[-1, ] # exclude the first empty row


### _______________________________________________________________________ ####
### @@@ PART III. MODEL SELECTION @@@ ####
## > III-1. FDR Correction for Calibration Estimates ####
result.models$beta_ATE_p_fdr <- p.adjust(result.models$beta_ATE_p, "fdr")
result.models$beta_ITE_p_fdr <- p.adjust(result.models$beta_ITE_p, "fdr")
result.models$ate_p_fdr <- p.adjust(result.models$ATE_p, "fdr")

## > III-2. Assessing Fit Index ####
result.models$fit_index <- abs(1 - result.models$beta_ATE_est) + abs(1 - result.models$beta_ITE_est)

## > III-3. Model Selection ####
result.models.pass <- result.models[result.models$beta_ATE_p_fdr < .05 & 
                                      result.models$beta_ITE_p_fdr < .05 & # models passing the calibration criteria
                                      result.models$min_e_hat >= .05 & 
                                      result.models$max_e_hat < .95, ]     # and fulfilling the overlap criteria

best.model.var_num <- result.models.pass[which.min(result.models.pass$fit_index), 'var_num'] 
best.model.var <- get(paste0('var_list_', as.character(best.model.var_num)))

selected <- best.model.var # key moderators chosen in the best model


### _______________________________________________________________________ ####
### @@@ PART IV. PERFORMANCE EVALUATION @@@ ####
## > IV-1. Fitting the Best Model ####
# selecting key moderators
X.best <- subset(data, select = c(selected))

# fit the GRF model
forest_list <- list()

for (seed_ind in 1:length(seeds)){
  
  print(paste('seed_ind', seed_ind, sep=' = '))
  
  forest <- causal_forest(X.best, Y, W, 
                          Y.hat = NULL, W.hat = NULL, 
                          compute.oob.predictions = FALSE, 
                          clusters = site_id_l,
                          num.trees = n.trees, 
                          tune.parameters = 'all',
                          num.threads = 16,
                          seed = seeds[seed_ind])
  forest_list[[paste0('seed', seed_ind)]] <- forest
}

# performing seed ensembles and creating the best 'big' model
best_model <- merge_forests(forest_list, compute.oob.predictions = TRUE)


## > IV-2. Assessing ITE Prediction in the trained dataset ####
ITE.train.pred <- predict(best_model)$predictions
ITE.train.true <- data$theta

ITE.train.coef <- cor.test(ITE.train.pred, ITE.train.true)$estimate[[1]]
ITE.train.pvalue <- cor.test(ITE.train.pred, ITE.train.true)$p.value


## > IV-3. Assessing ITE Prediction in the independent dataset ####
# loading test-set
test.data <- read.csv("../data/test_nonlin_weak.csv") 
X.test <- subset(test.data, select = c(selected))

# predicting ITE for new dataset
ITE.test.pred <- predict(best_model, newdata = X.test)$predictions
ITE.test.true <- test.data$theta

ITE.test.coef <- cor.test(ITE.test.pred, ITE.test.true)$estimate[[1]]
ITE.test.pvalue <- cor.test(ITE.test.pred, ITE.test.true)$p.value

## > IV-4. Evaluating Variable Selection ####
hte_factors <- c('smri_vol_scs_amygdalarh', 'smri_vol_cdk_cdacaterh', 'smri_vol_cdk_parahpallh') # real variables generating HTE
all_variables <- names(data)[-c(1:4, 19)] # except for "y", "theta", "w", "src_subject_id", "site_id_l"

TP <- sum(selected %in% hte_factors)
FP <- sum(selected %in% setdiff(selected, hte_factors))
FN <- sum(hte_factors %in% setdiff(hte_factors, selected))
TN <- length(setdiff(all_variables, union(hte_factors, selected)))

PRE <- TP / (TP + FP)
REC <- TP / (TP + FN)

F1_score <- 2 * PRE * REC / (PRE + REC)

## > IV-4. Final Report ####
print(paste0("[ITE Prediction: TRAIN] Our model predicts real ITE with R = ", round(ITE.train.coef, 3), " (P = ", ITE.train.pvalue, ")"))
print(paste0("[ITE Prediction: TEST]  Our model predicts real ITE with R = ", round(ITE.test.coef, 3), " (P = ", ITE.test.pvalue, ")"))
print(paste0("[Vars Selection] Our model identifies real HTE moderators with F1 = ", round(F1_score, 3)))


### _______________________________________________________________________ ####
### @@@ PART V. VISUALIZATION @@@ ####
## > V-1. Confusion Matrix ####
data.conf <- data.frame(
  Prediction = rep(c("Positive", "Negative"), each = 2),
  Actual = rep(c("Positive", "Negative"), 2),
  Count = c(TP, FN, FP, TN)
)

data.conf$ratio <- c(
  round(TP / (TP + FN), 3),
  round(FN / (TP + FN), 3),
  round(FP / (FP + TN), 3),
  round(TN / (FP + TN), 3)
)

fig3a.nonlin.ours <- ggplot(data.conf, aes(x = Actual, y = Prediction, fill = ratio)) +
  geom_tile(color = "white", linewidth = 1.2) +
  geom_text(aes(label = ratio), size = 6, color = "black", fontface = "bold") +
  scale_fill_gradient(low = "white", high = "#0868AC") +
  labs(
    title = "Confusion Matrix",
    x = "Actual",
    y = "Predicted"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid = element_blank()
  )

## > V-2. Scatter Plot - Train ####
data.train.coef <- data.frame(
  Pred = ITE.train.pred,
  True = ITE.train.true
)

lims.train <- range(c(data.train.coef$True, data.train.coef$Pred))

fig3b.nonlin.train <- ggplot(data.train.coef, aes(x = True, y = Pred)) +
  geom_point(alpha = 0.3, size = 1.5, color = "gray") +
  geom_smooth(method = "lm", se = TRUE, color = "#2C7BB6", linewidth = 1.0) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray40") +
  coord_fixed(ratio = 1, xlim = lims.train, ylim = lims.train) +
  labs(
    title = "",
    x = "True ITE",
    y = "Pred ITE"
  ) +
  theme_classic()

## > V-3. Scatter Plot - Test ####
data.test.coef <- data.frame(
  Pred = ITE.test.pred,
  True = ITE.test.true
)

lims.test <- range(c(data.test.coef$True, data.test.coef$Pred))

fig3b.nonlin.test <- ggplot(data.test.coef, aes(x = True, y = Pred)) +
  geom_point(alpha = 0.3, size = 1.5, color = "gray") +
  geom_smooth(method = "lm", se = TRUE, color = "#2C7BB6", linewidth = 1.0) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "gray40") +
  coord_fixed(ratio = 1, xlim = lims.test, ylim = lims.test) +
  labs(
    title = "",
    x = "True ITE",
    y = "Pred ITE"
  ) +
  theme_classic()